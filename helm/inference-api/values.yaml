replicaCount: 2

image:
  repository: ghcr.io/shaikirfanabegum/humana-ai-ml-devops-demo/inference-api
  tag: "latest"
  pullPolicy: IfNotPresent

nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  name: ""
  annotations: {}

podAnnotations: {}
podLabels: {}

service:
  type: ClusterIP
  port: 8080

ingress:
  enabled: false
  className: ""
  annotations: {}
  hosts:
    - host: inference.local
      paths:
        - path: /
          pathType: Prefix
  tls: []

resources:
  requests:
    cpu: 100m
    memory: 128Mi
  limits:
    cpu: 500m
    memory: 512Mi

# Probes: choose "http" (recommended if you expose an endpoint like /health)
# or "tcp" (works immediately without changing app code).
probes:
  type: tcp # http | tcp
  http:
    path: /health
  initialDelaySeconds: 10
  periodSeconds: 10
  timeoutSeconds: 2
  failureThreshold: 3

autoscaling:
  enabled: false
  minReplicas: 2
  maxReplicas: 6
  targetCPUUtilizationPercentage: 70

env: []
# Example:
# env:
#   - name: LOG_LEVEL
#     value: "info"

config:
  enabled: false
  data: {}
# Example:
# config:
#   enabled: true
#   data:
#     MODEL_NAME: "baseline"

secret:
  enabled: false
  data: {}
# NOTE: These should be base64-encoded if you use plain Kubernetes Secret manifests via Helm.
# Better: ExternalSecrets in real orgs, but keeping this demo simple.

nodeSelector: {}
tolerations: []
affinity: {}

securityContext:
  enabled: true
  runAsNonRoot: true
  runAsUser: 10001
  runAsGroup: 10001
  fsGroup: 10001
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: false
  capabilities:
    drop: ["ALL"]
